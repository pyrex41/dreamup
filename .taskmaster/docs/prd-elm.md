# Product Requirements Document: QA Agent Elm Frontend

## Overview

### Purpose
Build a lightweight, elegant Elm frontend that provides a user-friendly interface to run automated game tests and view detailed results. The frontend will be a static single-page application that interacts directly with the existing AWS Lambda and S3 infrastructure.

### Background
The DreamUp QA Agent is a production-ready Go-based automated testing platform that uses browser automation and LLM evaluation to assess web game playability. The system currently operates via CLI and AWS Lambda but lacks a visual interface. This PRD defines a web-based Elm frontend that leverages the existing Lambda function as a direct API endpoint and fetches results from S3 - requiring no additional backend services.

### Key Architectural Insight
The Lambda function (`cmd/lambda/main.go`) already serves as a complete API with well-defined JSON input/output contracts. The frontend can invoke it directly via Lambda Function URL and retrieve artifacts from S3, making this a pure static web application with zero backend overhead.

### Target Users
- **QA Testers** (primary): Run tests on new game builds without CLI
- **Game Producers/Managers**: Quickly check build quality and status
- **Developers**: Review bug reports and visual evidence from test runs

---

## Goals & Success Metrics

### Primary Goals
1. Enable zero-config test initiation via simple URL input
2. Display test execution status and completion
3. Present comprehensive test reports with AI evaluation
4. Showcase visual artifacts (screenshots) and console log summaries
5. Deploy as a static site with no backend infrastructure

### Success Metrics
- Users can initiate a test in <30 seconds
- Test results are viewable within 5 seconds of Lambda completion
- Application loads in <2 seconds
- Zero maintenance overhead (static hosting)
- 90% reduction in time-to-debug compared to CLI workflow

---

## User Stories

### Epic 1: Test Execution
**US-1.1**: As a user, I can see an input field where I can paste the URL of a web game.

**US-1.2**: As a user, I can click a "Run Test" button to submit the URL and start the QA process.

**US-1.3**: As a user, while the test is executing, the UI clearly indicates that a test is in progress (with a spinner or status message) to prevent duplicate submissions.

**US-1.4**: As a user, if the test fails due to an infrastructure error, I see a clear error message with actionable information.

### Epic 2: Report Viewing
**US-2.1**: As a user, once a test completes, the view automatically updates to show the test report summary without requiring page refresh.

**US-2.2**: As a user, I can clearly see the final status ("passed", "failed", "passed_with_warnings") and the overall AI score (e.g., 85/100).

**US-2.3**: As a user, I can see detailed evaluation metrics (loads correctly, interactivity, visual quality, error severity) with visual indicators.

**US-2.4**: As a user, I can read through the lists of "Issues" and "Recommendations" generated by the AI evaluator.

**US-2.5**: As a user, I can see test metadata (duration, timestamp, report ID) for reference.

### Epic 3: Visual Artifacts
**US-3.1**: As a user, I can view all screenshots captured during the test, each labeled with its context ("initial", "final").

**US-3.2**: As a developer, I want to view screenshots in a clear gallery format so that I can easily compare game states.

**US-3.3**: As a user, I can see a summary of the browser console logs showing total errors and warnings detected.

**US-3.4**: As a user, I can click a "Run Another Test" button to return to the input form and test a different URL.

---

## Core Features

### Feature 1: Test Submission Interface

**Description**: Simple form to initiate new tests

**Requirements**:
- **F1.1**: Single-field URL input with validation (must be valid HTTP/HTTPS URL)
- **F1.2**: Optional advanced settings panel:
  - Timeout slider (60-300 seconds, default: 280)
  - Metadata key-value pairs (for tagging tests)
  - S3 upload toggle (default: enabled)
- **F1.3**: Submit button with loading state during test execution
- **F1.4**: Client-side URL validation before submission
- **F1.5**: Display estimated completion time after submission

**Edge Cases**:
- Invalid URL format → Show inline validation error
- Test already running for URL → Option to view existing test or queue new one
- Lambda timeout → Display timeout error with partial results if available

---

### Feature 2: Test Execution Status

**Description**: Real-time feedback on running tests

**Requirements**:
- **F2.1**: Status indicator showing current phase:
  - Initializing
  - Loading game
  - Capturing initial screenshot
  - Waiting for gameplay
  - Capturing final screenshot
  - Analyzing results
  - Generating report
  - Completed
- **F2.2**: Progress bar or percentage completion
- **F2.3**: Elapsed time counter
- **F2.4**: Cancel test button (if feasible with Lambda architecture)
- **F2.5**: WebSocket or polling mechanism for real-time updates

**Technical Notes**:
- Consider WebSocket connection to Lambda/API Gateway for true real-time updates
- Fallback to polling every 2-3 seconds if WebSockets unavailable
- Store test execution state in browser localStorage for page refresh resilience

---

### Feature 3: Report Display

**Description**: Comprehensive view of test results

**Requirements**:
- **F3.1**: Report header showing:
  - Test status badge (Passed/Failed/Error)
  - Overall AI score (0-100 with color gradient: red→yellow→green)
  - Test duration
  - Timestamp
  - Report ID
  - Game URL (clickable link)
- **F3.2**: Evaluation metrics section:
  - Loads Correctly (boolean with ✓/✗)
  - Interactivity Score (0-100 with progress bar)
  - Visual Quality (0-100 with progress bar)
  - Error Severity (0-100 with progress bar)
- **F3.3**: Issues & Recommendations section:
  - Collapsible list of AI-identified issues
  - Collapsible list of recommendations
  - Each item with severity indicator (critical/warning/info)
- **F3.4**: AI Reasoning section:
  - Full-text reasoning from LLM evaluation
  - Syntax highlighting for code references if present
- **F3.5**: Metadata display (version, timestamps, custom tags)
- **F3.6**: Actions toolbar:
  - Share report link button (copy to clipboard)
  - Download report JSON button
  - Re-run test button

**UI/UX Notes**:
- Use card-based layout for visual hierarchy
- Color-code scores (0-40: red, 41-70: yellow, 71-100: green)
- Prioritize critical issues at top of list
- Collapsible sections to reduce cognitive load

---

### Feature 4: Screenshot Viewer

**Description**: Visual comparison of game states

**Requirements**:
- **F4.1**: Side-by-side view of initial and final screenshots
- **F4.2**: Toggle between side-by-side and overlay comparison modes:
  - Side-by-side: Two images horizontally aligned
  - Overlay: Slider to reveal initial vs final
  - Difference: Highlight changed pixels
- **F4.3**: Zoom controls (fit, 100%, 200%)
- **F4.4**: Full-screen mode for detailed inspection
- **F4.5**: Screenshot metadata:
  - Capture timestamp
  - Resolution
  - Context label (initial/final)
- **F4.6**: Download individual screenshots

**Technical Implementation**:
- Lazy load images from S3 URLs
- Use canvas API for difference mode if needed
- Implement pinch-to-zoom for mobile (future consideration)

---

### Feature 5: Console Log Viewer

**Description**: Filterable, searchable console output

**Requirements**:
- **F5.1**: Log entry list with:
  - Timestamp
  - Log level badge (error/warning/info/debug)
  - Message text
  - Source file/line (if available)
- **F5.2**: Filter controls:
  - Level toggles (show/hide errors, warnings, info, debug)
  - Quick filter: "Show only errors" button
- **F5.3**: Search functionality:
  - Real-time text search across log messages
  - Highlight matching terms
- **F5.4**: Summary statistics:
  - Total log count
  - Error count (with red badge)
  - Warning count (with yellow badge)
- **F5.5**: Virtual scrolling for performance with large log files
- **F5.6**: Export logs as JSON or text file
- **F5.7**: Syntax highlighting for stack traces

**Technical Implementation**:
- Use `elm-virtual-list` or similar for efficient rendering
- Consider debouncing search input (300ms)
- Parse structured logs from backend JSON format

---

### Feature 6: Test History & Search

**Description**: Browse and filter past test results

**Requirements**:
- **F6.1**: Paginated table/list of historical tests showing:
  - Status icon
  - Game URL (truncated with tooltip)
  - Score
  - Timestamp
  - Duration
  - Report ID
- **F6.2**: Sort by:
  - Timestamp (newest/oldest)
  - Score (highest/lowest)
  - Duration (shortest/longest)
- **F6.3**: Filter by:
  - Status (passed/failed/error)
  - Date range picker
  - URL substring search
  - Score range (slider)
- **F6.4**: Pagination controls (prev/next, page numbers)
- **F6.5**: Load more / infinite scroll option
- **F6.6**: Click any row to navigate to full report view

**API Considerations**:
- Backend needs to expose list endpoint: `GET /api/reports?page=1&limit=20&status=failed&from=2025-01-01`
- Response should include total count for pagination

---

## Technical Architecture

### Frontend Stack
- **Language**: Elm 0.19.1
- **Build Tool**: Vite with elm-vite plugin or webpack with elm-loader
- **HTTP Client**: `elm/http` for API requests
- **Routing**: `elm/browser` with `Browser.application`
- **JSON Decoding**: `elm/json` with custom decoders for API responses
- **UI Components**: Custom Elm HTML or elm-ui for layout
- **Date/Time**: `justinmimbs/time-extra` for date formatting

### Backend Integration Points

#### API Endpoints (to be created or exposed)

```
POST /api/tests
Request: { "game_url": string, "timeout"?: int, "metadata"?: object }
Response: { "test_id": string, "status": "queued" }

GET /api/tests/{test_id}
Response: { "status": string, "progress"?: int, "report"?: Report }

GET /api/tests/{test_id}/report
Response: Report (full JSON structure)

GET /api/reports?page=1&limit=20&status=passed
Response: { "reports": Report[], "total": int, "page": int }

WebSocket /api/tests/{test_id}/status
Messages: { "status": string, "progress": int, "phase": string }
```

#### S3 Asset URLs
- Screenshots: `https://s3.amazonaws.com/{bucket}/{report_id}/screenshot-{context}.png`
- Console logs: `https://s3.amazonaws.com/{bucket}/{report_id}/console.log`
- Report JSON: `https://s3.amazonaws.com/{bucket}/{report_id}/report.json`

### State Management

**Elm Architecture Pattern**:
```elm
type alias Model =
    { currentTest : Maybe TestExecution
    , selectedReport : Maybe Report
    , reportHistory : List ReportSummary
    , filters : FilterState
    , route : Route
    }

type Msg
    = SubmitTest String TestConfig
    | TestStatusUpdated TestStatus
    | TestCompleted Report
    | LoadReport String
    | ReportLoaded Report
    | FilterChanged Filter
    | NavigateTo Route
    
type Route
    = Home
    | NewTest
    | ReportView String
    | History
```

### Data Models

```elm
type alias Report =
    { reportId : String
    , gameUrl : String
    , duration : Float
    , timestamp : Time.Posix
    , summary : Summary
    , score : Maybe Score
    , screenshots : List Screenshot
    , consoleLogs : List ConsoleLog
    , metadata : Dict String String
    }

type alias Score =
    { overallScore : Int
    , loadsCorrectly : Bool
    , interactivityScore : Int
    , visualQuality : Int
    , errorSeverity : Int
    , issues : List String
    , recommendations : List String
    , reasoning : String
    }

type alias Screenshot =
    { context : String  -- "initial" | "final"
    , filepath : String
    , s3Url : Maybe String
    , timestamp : Time.Posix
    }

type alias ConsoleLog =
    { level : LogLevel
    , message : String
    , timestamp : Time.Posix
    , source : Maybe String
    }

type LogLevel = Error | Warning | Info | Debug
```

---

## UI/UX Design Guidelines

### Visual Design Principles
1. **Clarity**: Prioritize information hierarchy with clear typography
2. **Efficiency**: Minimize clicks to access critical information
3. **Consistency**: Use consistent spacing, colors, and component patterns
4. **Accessibility**: WCAG 2.1 AA compliance (color contrast, keyboard navigation)

### Color Palette
- **Primary**: Blue (#3B82F6) - Actions, links
- **Success**: Green (#10B981) - Passed tests, positive indicators
- **Warning**: Yellow (#F59E0B) - Warnings, moderate issues
- **Error**: Red (#EF4444) - Errors, critical issues
- **Neutral**: Gray scale (#F3F4F6 → #1F2937)

### Typography
- **Headers**: System UI font stack (San Francisco, Segoe UI, Roboto)
- **Body**: 16px base, 1.5 line height
- **Code**: Monospace (Fira Code, SF Mono, Consolas)

### Layout
- **Max width**: 1280px for primary content
- **Spacing**: 8px base unit (multiples of 8)
- **Responsive breakpoints**:
  - Mobile: <640px
  - Tablet: 640-1024px
  - Desktop: >1024px

### Component Examples

**Status Badge**:
```
[Passed] - Green background, white text, rounded
[Failed] - Red background, white text, rounded
[Running] - Blue background, white text, rounded, pulsing animation
```

**Score Display**:
```
Overall Score: [85]/100  [█████████░] (visual bar)
```

**Screenshot Comparison**:
```
┌─────────────────┬─────────────────┐
│   Initial       │   Final         │
│   [Screenshot]  │   [Screenshot]  │
└─────────────────┴─────────────────┘
[Side-by-side] [Overlay] [Difference]
```

---

## Implementation Phases

### Phase 1: MVP (Week 1-2)
- Basic test submission form
- Simple report display (summary only)
- Screenshot viewer (side-by-side only)
- Hardcoded API endpoint configuration

**Deliverables**:
- Working Elm application with test submission
- Report view with basic metrics
- Screenshot display
- Minimal styling (functional, not polished)

### Phase 2: Enhanced Features (Week 3-4)
- Real-time status updates (polling)
- Complete report display (all sections)
- Console log viewer with filtering
- Test history list (no search yet)
- Improved styling and responsive layout

**Deliverables**:
- Full report feature set
- Log viewer with level filtering
- History pagination
- Professional UI design

### Phase 3: Advanced Features (Week 5-6)
- WebSocket real-time updates
- Advanced screenshot comparison (overlay, difference modes)
- Search and filter in history
- Download/export functionality
- Error handling and edge cases

**Deliverables**:
- Production-ready application
- All user stories implemented
- Comprehensive error handling
- Performance optimization

### Phase 4: Polish & Deploy (Week 7)
- Accessibility audit and fixes
- Cross-browser testing
- Performance optimization
- Documentation
- Deploy to production

---

## API Requirements

### Backend Changes Needed

1. **REST API Wrapper**: Create an HTTP API layer over Lambda function
   - Could use API Gateway + Lambda integration
   - Or standalone Go HTTP server that invokes Lambda

2. **List Reports Endpoint**: 
   ```
   GET /api/reports
   Query params: page, limit, status, from_date, to_date, url_contains
   ```

3. **Status Polling Endpoint**:
   ```
   GET /api/tests/{test_id}/status
   Response: { "status": "running", "phase": "capturing_screenshots", "progress": 60 }
   ```

4. **CORS Configuration**: Enable CORS headers for frontend origin

5. **WebSocket Support** (optional for Phase 3):
   - API Gateway WebSocket API
   - Broadcast test status updates to connected clients

---

## Non-Functional Requirements

### Performance
- **Initial Load**: <2 seconds for empty state
- **Report Load**: <1 second for cached reports, <3 seconds for S3 fetch
- **Screenshot Load**: Progressive loading with placeholders
- **Log Rendering**: Handle 10,000+ log entries without UI freezing

### Security
- **HTTPS Only**: All API communication over TLS
- **CORS**: Restrict to known frontend domains
- **Report IDs**: Use UUIDs to prevent enumeration attacks
- **S3 URLs**: Pre-signed URLs with expiration (1 hour)

### Reliability
- **Error Handling**: Graceful degradation for network failures
- **Retry Logic**: Exponential backoff for failed API requests
- **Offline Indication**: Clear message when backend unreachable
- **State Persistence**: Save test IDs to localStorage for recovery

### Browser Support
- Chrome 90+ (primary)
- Firefox 88+ (primary)
- Safari 14+ (secondary)
- Edge 90+ (secondary)

---

## Open Questions

1. **Authentication**: Do we need user authentication, or is this internal-only?
   - If yes, consider OAuth2/OIDC integration
   - If no, consider IP whitelisting at API Gateway

2. **Concurrent Tests**: Should users be able to run multiple tests simultaneously?
   - Frontend needs to track multiple test IDs
   - Backend needs queue management

3. **Report Retention**: How long should reports be stored in S3?
   - Consider lifecycle policy (e.g., 30 days)
   - Archive old reports to Glacier?

4. **Real-time Updates**: WebSocket vs polling trade-offs
   - WebSockets: More efficient, complex setup
   - Polling: Simpler, slightly higher latency

5. **Mobile Support**: Is mobile browser support in scope?
   - If yes, prioritize responsive design from Phase 1
   - Consider touch gestures for screenshot comparison

---

## Success Criteria

### Launch Criteria (MVP)
- [ ] User can submit a test and view basic results
- [ ] Screenshots are displayed correctly
- [ ] No critical bugs in primary workflows
- [ ] Deployed to staging environment

### Full Release Criteria
- [ ] All user stories implemented and tested
- [ ] Performance meets NFRs
- [ ] Accessibility audit passed
- [ ] Documentation complete
- [ ] Production deployment successful
- [ ] Positive feedback from initial user cohort (3+ users)

---

## Appendix

### Elm Package Dependencies
```elm
{
    "dependencies": {
        "elm/core": "1.0.5",
        "elm/html": "1.0.0",
        "elm/http": "2.0.0",
        "elm/json": "1.1.3",
        "elm/browser": "1.0.2",
        "elm/url": "1.0.0",
        "elm/time": "1.0.0",
        "justinmimbs/time-extra": "1.1.1",
        "elm-community/list-extra": "8.7.0"
    }
}
```

### Sample API Response (Report JSON)
```json
{
  "report_id": "550e8400-e29b-41d4-a716-446655440000",
  "game_url": "https://example.com/game",
  "duration": 12.5,
  "timestamp": "2025-11-03T10:30:00Z",
  "summary": {
    "status": "passed",
    "passed_checks": ["Game loads", "No critical errors"],
    "failed_checks": [],
    "critical_issues": []
  },
  "score": {
    "overall_score": 85,
    "loads_correctly": true,
    "interactivity_score": 80,
    "visual_quality": 90,
    "error_severity": 85,
    "issues": ["Minor CSS rendering issue on mobile"],
    "recommendations": ["Consider optimizing asset loading"],
    "reasoning": "Game loads successfully with minor warnings..."
  },
  "screenshots": [
    {
      "context": "initial",
      "filepath": "/tmp/screenshot-initial.png",
      "s3_url": "https://s3.amazonaws.com/bucket/report-id/initial.png",
      "timestamp": "2025-11-03T10:30:05Z"
    },
    {
      "context": "final",
      "filepath": "/tmp/screenshot-final.png",
      "s3_url": "https://s3.amazonaws.com/bucket/report-id/final.png",
      "timestamp": "2025-11-03T10:30:10Z"
    }
  ],
  "console_logs": [
    {
      "level": "error",
      "message": "Failed to load asset: texture.png",
      "timestamp": "2025-11-03T10:30:07Z",
      "source": "game.js:145"
    }
  ],
  "metadata": {
    "agent_version": "1.0.0",
    "browser": "chrome-headless",
    "lambda_execution": "true"
  }
}
```

### Reference Links
- Elm Guide: https://guide.elm-lang.org/
- Elm HTTP: https://package.elm-lang.org/packages/elm/http/latest/
- Browser Application: https://package.elm-lang.org/packages/elm/browser/latest/Browser

---

**Document Version**: 1.0  
**Last Updated**: 2025-11-03  
**Author**: Product/Engineering Team  
**Status**: Draft for Review
